{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nocd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.sparse as sp\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "from sklearn.preprocessing import normalize\n",
    "from scipy.sparse import csr_matrix\n",
    "import pandas as pd\n",
    "\n",
    "import dgl\n",
    "import numpy as np\n",
    "import torch as th\n",
    "from dgl.nn import EdgeGATConv\n",
    "from dgl.nn import GATConv\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# torch.set_default_tensor_type(torch.cuda.FloatTensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0+cu121\n"
     ]
    }
   ],
   "source": [
    "print(dgl.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('subgraph.pkl', 'rb') as file:\n",
    "    subgraph = pickle.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "subgraph.ndata['feature']=subgraph.ndata['feature'].to(torch.float)\n",
    "subgraph.edata['feature']=subgraph.edata['feature'].to(torch.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EdgeGATNet(nn.Module):\n",
    "    def __init__(self, in_node_feats, in_edge_feats, hidden_feats,out_feats):\n",
    "        super(EdgeGATNet, self).__init__()\n",
    "        self.edge_gat_conv1 = EdgeGATConv(in_node_feats, in_edge_feats,hidden_feats,1,allow_zero_in_degree=True)\n",
    "        self.edge_gat_conv2 = GATConv(hidden_feats, out_feats,1,allow_zero_in_degree=True)\n",
    "\n",
    "    def forward(self, g, node_feats, edge_feats):\n",
    "        # Update node and edge representations using EGAT layers\n",
    "        node_feats= self.edge_gat_conv1(g, node_feats, edge_feats)\n",
    "        node_feats= F.relu(node_feats)\n",
    "        node_feats= self.edge_gat_conv2(g, node_feats)\n",
    "\n",
    "        return node_feats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "in_node_feats = subgraph.ndata['feature'].shape[1]\n",
    "in_edge_feats = subgraph.edata['feature'].shape[1]\n",
    "hidden_feats = 64  # You can adjust this based on your graph and task\n",
    "out_feats = 2  # Number of communities you want to detect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the model\n",
    "model = EdgeGATNet(in_node_feats, in_edge_feats, hidden_feats, out_feats)\n",
    "\n",
    "# Assuming you have a data loader for your graph\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def deep_graph_infomax_loss(embeddings, pos_mask, neg_mask):\n",
    "    # Compute dot product between positive and negative samples\n",
    "    pos_score = torch.sum(embeddings * pos_mask, dim=-1)\n",
    "    neg_score = torch.sum(embeddings * neg_mask, dim=-1)\n",
    "\n",
    "    # Contrastive loss (maximize positive, minimize negative)\n",
    "    loss = -torch.log(torch.sigmoid(pos_score) + 1e-15) - torch.log(1 - torch.sigmoid(neg_score) + 1e-15)\n",
    "    return loss.mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the ModularityLoss module\n",
    "class ModularityLoss(nn.Module):\n",
    "    def __init__(self, g):\n",
    "        super(ModularityLoss, self).__init__()\n",
    "        self.g = g\n",
    "\n",
    "    def forward(self, node_embeddings, predicted_communities):\n",
    "        Q = self.compute_modularity(node_embeddings, predicted_communities)\n",
    "        loss = 1 - Q  # Minimize 1 - Modularity\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def compute_modularity(self, node_embeddings, predicted_communities):\n",
    "        communities = torch.tensor(predicted_communities)\n",
    "\n",
    "        # Construct a tensor for community assignment\n",
    "        community_assignment = torch.zeros((self.g.number_of_nodes(), len(communities)))\n",
    "        community_assignment.scatter_(1, communities.view(-1, 1), 1)\n",
    "\n",
    "        # Compute the modularity matrix\n",
    "        modularity_matrix = self.g.adjacency_matrix().to_dense() - torch.mm(community_assignment, community_assignment.t())\n",
    "\n",
    "        # Compute the modularity score\n",
    "        Q = torch.trace(torch.mm(torch.mm(node_embeddings.t(), modularity_matrix), node_embeddings))\n",
    "\n",
    "        return Q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "modularity_loss = ModularityLoss(subgraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "Cannot find DGL C++ sparse library at c:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\dgl\\dgl_sparse\\dgl_sparse_pytorch_2.2.1.dll",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[75], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m adj_matrix \u001b[38;5;241m=\u001b[39m \u001b[43msubgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjacency_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\dgl\\heterograph.py:3761\u001b[0m, in \u001b[0;36mDGLGraph.adjacency_matrix\u001b[1;34m(self, etype)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjacency_matrix\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3760\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Alias of :meth:`adj`\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3761\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\dgl\\heterograph.py:3823\u001b[0m, in \u001b[0;36mDGLGraph.adj\u001b[1;34m(self, etype, eweight_name)\u001b[0m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;66;03m# Temporal fix to introduce a dependency on torch\u001b[39;00m\n\u001b[0;32m   3821\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m-> 3823\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[0;32m   3825\u001b[0m etype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_canonical_etype(etype)\n\u001b[0;32m   3826\u001b[0m indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_edges(etype\u001b[38;5;241m=\u001b[39metype))\n",
      "File \u001b[1;32mc:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\dgl\\sparse\\__init__.py:43\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=W0703\u001b[39;00m\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load DGL C++ sparse library\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[43mload_dgl_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\dgl\\sparse\\__init__.py:35\u001b[0m, in \u001b[0;36mload_dgl_sparse\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdgl_sparse\u001b[39m\u001b[38;5;124m\"\u001b[39m, basename)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find DGL C++ sparse library at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     torch\u001b[38;5;241m.\u001b[39mclasses\u001b[38;5;241m.\u001b[39mload_library(path)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Cannot find DGL C++ sparse library at c:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\dgl\\dgl_sparse\\dgl_sparse_pytorch_2.2.1.dll"
     ]
    }
   ],
   "source": [
    "adj_matrix = subgraph.adjacency_matrix()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'sparse'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[74], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43madj_matrix\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m()\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'sparse'"
     ]
    }
   ],
   "source": [
    "adj_matrix.sparse()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACT\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    },
    {
     "ename": "FileNotFoundError",
     "evalue": "Cannot find DGL C++ sparse library at c:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\dgl\\dgl_sparse\\dgl_sparse_pytorch_2.2.1.dll",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[59], line 15\u001b[0m\n\u001b[0;32m     10\u001b[0m predicted_communities \u001b[38;5;241m=\u001b[39m predicted_communities\u001b[38;5;241m.\u001b[39mastype(np\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m     12\u001b[0m \u001b[38;5;66;03m# node_feats=node_feats.to(torch.int64)\u001b[39;00m\n\u001b[0;32m     13\u001b[0m \n\u001b[0;32m     14\u001b[0m \u001b[38;5;66;03m# # Compute the modularity-based loss\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodularity_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_communities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# optimizer.zero_grad()\u001b[39;00m\n\u001b[0;32m     18\u001b[0m \u001b[38;5;66;03m# loss.backward()\u001b[39;00m\n\u001b[0;32m     19\u001b[0m \u001b[38;5;66;03m# optimizer.step()\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[49], line 8\u001b[0m, in \u001b[0;36mModularityLoss.forward\u001b[1;34m(self, node_embeddings, predicted_communities)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_embeddings, predicted_communities):\n\u001b[1;32m----> 8\u001b[0m     Q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_modularity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_communities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m Q  \u001b[38;5;66;03m# Minimize 1 - Modularity\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "Cell \u001b[1;32mIn[49], line 21\u001b[0m, in \u001b[0;36mModularityLoss.compute_modularity\u001b[1;34m(self, node_embeddings, predicted_communities)\u001b[0m\n\u001b[0;32m     18\u001b[0m community_assignment\u001b[38;5;241m.\u001b[39mscatter_(\u001b[38;5;241m1\u001b[39m, communities\u001b[38;5;241m.\u001b[39mview(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m), \u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Compute the modularity matrix\u001b[39;00m\n\u001b[1;32m---> 21\u001b[0m modularity_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mg\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madjacency_matrix\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mto_dense() \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(community_assignment, community_assignment\u001b[38;5;241m.\u001b[39mt())\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m# Compute the modularity score\u001b[39;00m\n\u001b[0;32m     24\u001b[0m Q \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mtrace(torch\u001b[38;5;241m.\u001b[39mmm(torch\u001b[38;5;241m.\u001b[39mmm(node_embeddings\u001b[38;5;241m.\u001b[39mt(), modularity_matrix), node_embeddings))\n",
      "File \u001b[1;32mc:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\dgl\\heterograph.py:3761\u001b[0m, in \u001b[0;36mDGLGraph.adjacency_matrix\u001b[1;34m(self, etype)\u001b[0m\n\u001b[0;32m   3759\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madjacency_matrix\u001b[39m(\u001b[38;5;28mself\u001b[39m, etype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[0;32m   3760\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Alias of :meth:`adj`\"\"\"\u001b[39;00m\n\u001b[1;32m-> 3761\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madj\u001b[49m\u001b[43m(\u001b[49m\u001b[43metype\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\dgl\\heterograph.py:3823\u001b[0m, in \u001b[0;36mDGLGraph.adj\u001b[1;34m(self, etype, eweight_name)\u001b[0m\n\u001b[0;32m   3820\u001b[0m \u001b[38;5;66;03m# Temporal fix to introduce a dependency on torch\u001b[39;00m\n\u001b[0;32m   3821\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m-> 3823\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01msparse\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m spmatrix\n\u001b[0;32m   3825\u001b[0m etype \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_canonical_etype(etype)\n\u001b[0;32m   3826\u001b[0m indices \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mall_edges(etype\u001b[38;5;241m=\u001b[39metype))\n",
      "File \u001b[1;32mc:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\dgl\\sparse\\__init__.py:43\u001b[0m\n\u001b[0;32m     39\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m:  \u001b[38;5;66;03m# pylint: disable=W0703\u001b[39;00m\n\u001b[0;32m     40\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mImportError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot load DGL C++ sparse library\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 43\u001b[0m \u001b[43mload_dgl_sparse\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\dgl\\sparse\\__init__.py:35\u001b[0m, in \u001b[0;36mload_dgl_sparse\u001b[1;34m()\u001b[0m\n\u001b[0;32m     33\u001b[0m path \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(dirname, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdgl_sparse\u001b[39m\u001b[38;5;124m\"\u001b[39m, basename)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mexists(path):\n\u001b[1;32m---> 35\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mFileNotFoundError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot find DGL C++ sparse library at \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpath\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     37\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     38\u001b[0m     torch\u001b[38;5;241m.\u001b[39mclasses\u001b[38;5;241m.\u001b[39mload_library(path)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: Cannot find DGL C++ sparse library at c:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\dgl\\dgl_sparse\\dgl_sparse_pytorch_2.2.1.dll"
     ]
    }
   ],
   "source": [
    "model.train()\n",
    "node_feats= model(subgraph, subgraph.ndata['feature'], subgraph.edata['feature'])\n",
    "\n",
    "node_feats=node_feats.reshape(node_feats.shape[0],node_feats.shape[3])\n",
    "\n",
    "# Apply K-means clustering to the learned embeddings\n",
    "kmeans = KMeans(n_clusters=out_feats, random_state=42)\n",
    "predicted_communities = kmeans.fit_predict(node_feats.detach().numpy())\n",
    "\n",
    "predicted_communities = predicted_communities.astype(np.int64)\n",
    "\n",
    "# node_feats=node_feats.to(torch.int64)\n",
    "\n",
    "# # Compute the modularity-based loss\n",
    "loss = modularity_loss(node_feats, predicted_communities)\n",
    "\n",
    "# optimizer.zero_grad()\n",
    "# loss.backward()\n",
    "# optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, ..., 0, 0, 1])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predicted_communities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "processing:   0%|          | 0/100 [00:00<?, ?it/s]C:\\Users\\ACT\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "processing:   0%|          | 0/100 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "scatter(): Expected dtype int64 for index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[54], line 18\u001b[0m\n\u001b[0;32m     15\u001b[0m node_feats\u001b[38;5;241m=\u001b[39mnode_feats\u001b[38;5;241m.\u001b[39mto(torch\u001b[38;5;241m.\u001b[39mint64)\n\u001b[0;32m     17\u001b[0m \u001b[38;5;66;03m# Compute the modularity-based loss\u001b[39;00m\n\u001b[1;32m---> 18\u001b[0m loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodularity_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_feats\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_communities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m optimizer\u001b[38;5;241m.\u001b[39mzero_grad()\n\u001b[0;32m     21\u001b[0m loss\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[1;32mc:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1511\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1509\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[0;32m   1510\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1511\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\ACT\\anaconda3\\envs\\nocd\\Lib\\site-packages\\torch\\nn\\modules\\module.py:1520\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1515\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[0;32m   1516\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[0;32m   1517\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[0;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[0;32m   1519\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[1;32m-> 1520\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1522\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m   1523\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[1;32mIn[49], line 8\u001b[0m, in \u001b[0;36mModularityLoss.forward\u001b[1;34m(self, node_embeddings, predicted_communities)\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, node_embeddings, predicted_communities):\n\u001b[1;32m----> 8\u001b[0m     Q \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompute_modularity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnode_embeddings\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpredicted_communities\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m      9\u001b[0m     loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m-\u001b[39m Q  \u001b[38;5;66;03m# Minimize 1 - Modularity\u001b[39;00m\n\u001b[0;32m     11\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m loss\n",
      "Cell \u001b[1;32mIn[49], line 18\u001b[0m, in \u001b[0;36mModularityLoss.compute_modularity\u001b[1;34m(self, node_embeddings, predicted_communities)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m# Construct a tensor for community assignment\u001b[39;00m\n\u001b[0;32m     17\u001b[0m community_assignment \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mzeros((\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\u001b[38;5;241m.\u001b[39mnumber_of_nodes(), \u001b[38;5;28mlen\u001b[39m(communities)))\n\u001b[1;32m---> 18\u001b[0m \u001b[43mcommunity_assignment\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscatter_\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcommunities\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mview\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     20\u001b[0m \u001b[38;5;66;03m# Compute the modularity matrix\u001b[39;00m\n\u001b[0;32m     21\u001b[0m modularity_matrix \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mg\u001b[38;5;241m.\u001b[39madjacency_matrix()\u001b[38;5;241m.\u001b[39mto_dense() \u001b[38;5;241m-\u001b[39m torch\u001b[38;5;241m.\u001b[39mmm(community_assignment, community_assignment\u001b[38;5;241m.\u001b[39mt())\n",
      "\u001b[1;31mRuntimeError\u001b[0m: scatter(): Expected dtype int64 for index"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "num_epochs=100\n",
    "# Training loop\n",
    "for epoch in tqdm(range(num_epochs),desc='processing'):\n",
    "    model.train()\n",
    "    node_feats= model(subgraph, subgraph.ndata['feature'], subgraph.edata['feature'])\n",
    "    \n",
    "    node_feats=node_feats.reshape(node_feats.shape[0],node_feats.shape[3])\n",
    "    \n",
    "    # Apply K-means clustering to the learned embeddings\n",
    "    kmeans = KMeans(n_clusters=out_feats, random_state=42)\n",
    "    predicted_communities = kmeans.fit_predict(node_feats.detach().numpy())\n",
    "    \n",
    "    node_feats=node_feats.to(torch.int64)\n",
    "\n",
    "    # Compute the modularity-based loss\n",
    "    loss = modularity_loss(node_feats, predicted_communities)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss.backward()\n",
    "    optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# After training, you can use the learned embeddings for downstream tasks\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    node_embeddings = model(subgraph, subgraph.ndata['feature'], subgraph.edata['feature'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings=node_embeddings.reshape(10693,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "node_embeddings=node_embeddings.mean(dim=(1,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10693"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "node_embeddings.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACT\\AppData\\Roaming\\Python\\Python311\\site-packages\\sklearn\\cluster\\_kmeans.py:1416: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# Assuming 'node_embeddings' contains the learned node embeddings\n",
    "# It should be a numpy array with shape (num_nodes, embedding_dim)\n",
    "\n",
    "# Specify the number of communities you want to detect (you may need to tune this)\n",
    "num_communities = 2\n",
    "\n",
    "# Apply K-means clustering to the learned embeddings\n",
    "kmeans = KMeans(n_clusters=num_communities, random_state=42)\n",
    "community_assignments = kmeans.fit_predict(node_embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique communities\n",
    "unique_communities = np.unique(community_assignments)\n",
    "\n",
    "# Create the community affiliation matrix using one-hot encoding\n",
    "community_affiliation_matrix = np.eye(len(unique_communities))[community_assignments]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_pred=community_affiliation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\ACT\\AppData\\Local\\Temp\\ipykernel_28956\\1961254491.py:6: FutureWarning: DataFrame.groupby with axis=1 is deprecated. Do `frame.T.groupby(...)` without axis instead.\n",
      "  affiliation_matrix = pd.get_dummies(df_selected_species, columns=['species_id']).groupby(level=0, axis=1).max()\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('./dataset/ogbn_proteins/raw/node_species.csv.gz', header=None, names=['species_id'])\n",
    "selected_species=[4932,511145]\n",
    "\n",
    "df_selected_species = df[df['species_id'].isin(selected_species)]\n",
    "\n",
    "affiliation_matrix = pd.get_dummies(df_selected_species, columns=['species_id']).groupby(level=0, axis=1).max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_gt=affiliation_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10693, 2)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10693, 2)"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z_gt.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_comlist(community_matrix):\n",
    "    transposed_matrix = np.transpose(community_matrix)\n",
    "\n",
    "    # Initialize an empty list to store tuples (community_id, nodes_list)\n",
    "    community_nodes_list = []\n",
    "\n",
    "    # Iterate through rows (communities)\n",
    "    for community_id, community_row in enumerate(transposed_matrix):\n",
    "        # Find nodes (columns) where the value is 1\n",
    "        community_nodes = np.where(community_row == 1)[0].tolist()\n",
    "        \n",
    "        # Append a tuple to the list containing community ID and nodes list\n",
    "        community_nodes_list.append(community_nodes)\n",
    "    \n",
    "    return community_nodes_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "Z_gt=Z_gt=affiliation_matrix.astype('int').values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0011373898786996338"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nmi = nocd.metrics.overlapping_nmi(Z_pred, Z_gt)\n",
    "nmi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MatchingResult(score=0.001146597878475153, std=None)\n"
     ]
    }
   ],
   "source": [
    "from cdlib import NodeClustering\n",
    "from cdlib import evaluation\n",
    "import networkx as nx\n",
    "\n",
    "G=dgl.to_networkx(subgraph)\n",
    "\n",
    "coms1=get_comlist(Z_gt)\n",
    "coms2=get_comlist(Z_pred)\n",
    "\n",
    "communities1=NodeClustering(coms1,G)\n",
    "communities2=NodeClustering(coms2,G)\n",
    "\n",
    "onmi=evaluation.overlapping_normalized_mutual_information_LFK(communities1,communities2)\n",
    "print(onmi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nocd",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
